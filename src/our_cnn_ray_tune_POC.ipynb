{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "import pandas as pd\n",
    "from data_utils.cifar10_testset import CIFAR10Testset\n",
    "import data_utils.data_loading as data_load\n",
    "from custom_nets.vgglike import VGGLike\n",
    "import random\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkHyperparamsTuner():\n",
    "\n",
    "    MAX_EPOCHS = 2\n",
    "    GPUs_COUNT = 0\n",
    "    CPUs_COUNT = 4\n",
    "\n",
    "    @staticmethod\n",
    "    def tune_network(train_function, tune_config: dict, device: str, num_samples: int):\n",
    "        \n",
    "            scheduler = ASHAScheduler(\n",
    "                metric='loss',\n",
    "                mode='min',\n",
    "                max_t=NetworkHyperparamsTuner.MAX_EPOCHS,\n",
    "                grace_period=1,\n",
    "                reduction_factor=2\n",
    "            )\n",
    "\n",
    "            reporter = CLIReporter(\n",
    "                metric_columns=['loss', 'accuracy', 'training_iteration']\n",
    "            )\n",
    "\n",
    "            results = tune.run(\n",
    "                partial(train_function, device=device),\n",
    "                resources_per_trial={'cpu': NetworkHyperparamsTuner.CPUs_COUNT, 'gpu': NetworkHyperparamsTuner.GPUs_COUNT},\n",
    "                config=tune_config,\n",
    "                num_samples=num_samples,\n",
    "                scheduler=scheduler,\n",
    "                progress_reporter=reporter,\n",
    "                local_dir='../raytune_logs'\n",
    "            )\n",
    "\n",
    "            return results\n",
    "\n",
    "    @staticmethod\n",
    "    def general_tune_network(net, criterion, optimizer, checkpoint_dir, device):\n",
    "        if (device == 'cuda:0' and torch.cuda.device_count() > 1):\n",
    "            net = nn.DataParallel(net)\n",
    "        net.to(device)\n",
    "\n",
    "        if checkpoint_dir:\n",
    "            model_state, optimizer_state = torch.load(\n",
    "                os.path.join(checkpoint_dir, 'checkpoint'))\n",
    "            net.load_state_dict(model_state)\n",
    "            optimizer.load_state_dict(optimizer_state)\n",
    "        \n",
    "        trainloader, valloader = NetworkHyperparamsTuner.__load_data()\n",
    "\n",
    "        for epoch in range(NetworkHyperparamsTuner.MAX_EPOCHS):\n",
    "            train_loss, train_acc = NetworkHyperparamsTuner.__train_one_epoch(trainloader, net, optimizer, criterion, epoch, device)\n",
    "            \n",
    "            val_loss, val_acc = NetworkHyperparamsTuner.__validate_one_epoch(valloader, net, criterion, device)\n",
    "\n",
    "            with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "                path = os.path.join(checkpoint_dir, 'checkpoint')\n",
    "                torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "            writer = SummaryWriter(tune.get_trial_dir())\n",
    "            print(tune.get_trial_dir())\n",
    "            writer.add_scalars('loss',\n",
    "                                {'Training': train_loss, 'Validation': val_loss},\n",
    "                                epoch)\n",
    "            writer.add_scalars('acc',\n",
    "                                {'Training': train_acc, 'Validation': val_acc},\n",
    "                                epoch)\n",
    "\n",
    "            tune.report(loss=val_loss, accuracy=val_acc)\n",
    "        \n",
    "        print('Finished Training')\n",
    "\n",
    "\n",
    "    @staticmethod \n",
    "    def __load_data():\n",
    "        batch_size = 32\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "        return data_load.load_train_data(transform, batch_size)\n",
    "\n",
    "    @staticmethod\n",
    "    def __train_one_epoch(trainloader, net: nn.Module, optimizer, criterion, epoch, device):\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(trainloader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "\n",
    "        train_loss = running_loss / epoch_steps\n",
    "        train_acc = correct / total\n",
    "\n",
    "        return train_loss, train_acc\n",
    "\n",
    "    @staticmethod\n",
    "    def __validate_one_epoch(valloader, net, criterion, device):\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0.0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(valloader):\n",
    "\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = net(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "\n",
    "        val_loss = val_loss / val_steps\n",
    "        val_acc = correct / total\n",
    "\n",
    "        return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkTester():\n",
    "\n",
    "    @staticmethod\n",
    "    def test_accuracy(net, device, net_name):\n",
    "        if not os.path.exists('../tests'):\n",
    "            os.makedirs('../tests')\n",
    "\n",
    "        net.to(device)\n",
    "        testloader, number_of_images = NetworkTester.__load_data()\n",
    "\n",
    "        classes = np.empty((number_of_images), dtype=object)\n",
    "\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images = data[0].to(device)\n",
    "                outputs = net(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                predicted = predicted.tolist()\n",
    "                for predicted_label in predicted:\n",
    "                    classes[total] = CIFAR10Testset.label_number_to_class[predicted_label]\n",
    "                    total += 1\n",
    "\n",
    "        pd.DataFrame(classes, index=range(1, total + 1), columns=['label']).to_csv('../tests/' + net_name + '.csv', index_label='id')\n",
    "\n",
    "    @staticmethod \n",
    "    def __load_data():\n",
    "        batch_size = 32\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "        return data_load.load_test_data(transform, batch_size)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuning & training\n",
    "def tune_net(config, checkpoint_dir=None, device=None):\n",
    "    net = VGGLike(config['dropout_factor'])\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    NetworkHyperparamsTuner.general_tune_network(net, criterion, optimizer, checkpoint_dir, device)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "config = {\n",
    "    'dropout_factor': tune.uniform(0.1, 0.5)\n",
    "}\n",
    "\n",
    "net_results = NetworkHyperparamsTuner.tune_network(tune_net, config, device, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_best_trial = net_results.get_best_trial('loss', 'min', 'last')\n",
    "net_best_trained_model = VGGLike(net_best_trial.config['dropout_factor'])\n",
    "\n",
    "net_best_checkpoint_dir = net_best_trial.checkpoint.value\n",
    "model_state, optimizer_state = torch.load(os.path.join(net_best_checkpoint_dir, 'checkpoint'))\n",
    "\n",
    "net_best_trained_model.load_state_dict(model_state)\n",
    "test_acc = NetworkTester.test_accuracy(net_best_trained_model, device, 'tuned')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "072b87cd3304d5c6ed11f7927857479580c8a3310790140c228e7c13bf0199a7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('dl_proj_cnn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
